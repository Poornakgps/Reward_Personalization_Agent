{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reward Recommendation Algorithm Prototype\n",
    "\n",
    "This notebook implements and evaluates different algorithms for reward recommendation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# For collaborative filtering\n",
    "from surprise import Dataset, Reader, SVD, KNNBasic\n",
    "from surprise.model_selection import cross_validate\n",
    "\n",
    "# Set visualization style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Load customers, rewards and events data\n",
    "with open('../data/customers.json', 'r') as f:\n",
    "    customers = json.load(f)\n",
    "    \n",
    "with open('../data/rewards.json', 'r') as f:\n",
    "    rewards = json.load(f)\n",
    "    \n",
    "with open('../data/events.json', 'r') as f:\n",
    "    events = json.load(f)\n",
    "    \n",
    "# Convert to DataFrames\n",
    "customers_df = pd.DataFrame(customers)\n",
    "rewards_df = pd.DataFrame(rewards)\n",
    "events_df = pd.DataFrame(events)\n",
    "\n",
    "print(f\"Loaded {len(customers_df)} customers, {len(rewards_df)} rewards, and {len(events_df)} events\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Filter events to get reward claims\n",
    "claims_df = events_df[events_df['event_type'] == 'reward_claim'].copy()\n",
    "\n",
    "# Extract reward ID from metadata\n",
    "claims_df['reward_id'] = claims_df['metadata'].apply(lambda x: x.get('reward_id', None))\n",
    "\n",
    "# Drop rows with missing reward_id\n",
    "claims_df = claims_df.dropna(subset=['reward_id'])\n",
    "\n",
    "# Create interactions dataframe for collaborative filtering\n",
    "interactions_df = claims_df[['customer_id', 'reward_id']].copy()\n",
    "\n",
    "# Add implicit rating (1 for claimed)\n",
    "interactions_df['rating'] = 1.0\n",
    "\n",
    "print(f\"Created {len(interactions_df)} customer-reward interactions\")\n",
    "interactions_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Extract customer features for content-based filtering\n",
    "def extract_customer_features(customer):\n",
    "    features = {}\n",
    "    \n",
    "    # Extract demographic features\n",
    "    attributes = customer.get('attributes', {})\n",
    "    features['age'] = attributes.get('age', 35)  # Default age\n",
    "    \n",
    "    # One-hot encode gender\n",
    "    gender = attributes.get('gender', 'unknown')\n",
    "    features['gender_male'] = 1 if gender == 'male' else 0\n",
    "    features['gender_female'] = 1 if gender == 'female' else 0\n",
    "    features['gender_other'] = 1 if gender not in ['male', 'female', 'unknown'] else 0\n",
    "    \n",
    "    # One-hot encode location\n",
    "    location = attributes.get('location', 'unknown')\n",
    "    features['location'] = location\n",
    "    \n",
    "    # Process interests\n",
    "    interests = attributes.get('interests', [])\n",
    "    features['interest_count'] = len(interests)\n",
    "    \n",
    "    # Track specific interests\n",
    "    common_interests = ['fashion', 'technology', 'sports', 'beauty', 'home', 'travel', 'food']\n",
    "    for interest in common_interests:\n",
    "        features[f'interest_{interest}'] = 1 if interest in interests else 0\n",
    "    \n",
    "    return features\n",
    "\n",
    "# Extract reward features for content-based filtering\n",
    "def extract_reward_features(reward):\n",
    "    features = {}\n",
    "    \n",
    "    # Basic attributes\n",
    "    features['value'] = reward.get('value', 0)\n",
    "    \n",
    "    # One-hot encode type\n",
    "    reward_type = reward.get('type', 'unknown')\n",
    "    features['type'] = reward_type\n",
    "    \n",
    "    # Extract conditions\n",
    "    conditions = reward.get('conditions', {})\n",
    "    features['has_min_purchase'] = 1 if 'min_purchase' in conditions else 0\n",
    "    features['min_purchase_value'] = conditions.get('min_purchase', 0) if 'min_purchase' in conditions else 0\n",
    "    \n",
    "    return features\n",
    "\n",
    "# Extract customer features\n",
    "customer_features = {}\n",
    "for customer in customers:\n",
    "    customer_id = customer.get('id')\n",
    "    customer_features[customer_id] = extract_customer_features(customer)\n",
    "\n",
    "# Extract reward features\n",
    "reward_features = {}\n",
    "for reward in rewards:\n",
    "    reward_id = reward.get('id')\n",
    "    reward_features[reward_id] = extract_reward_features(reward)\n",
    "\n",
    "# Convert to DataFrames\n",
    "customer_features_df = pd.DataFrame.from_dict(customer_features, orient='index')\n",
    "reward_features_df = pd.DataFrame.from_dict(reward_features, orient='index')\n",
    "\n",
    "print(f\"Extracted features for {len(customer_features_df)} customers and {len(reward_features_df)} rewards\")\n",
    "customer_features_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement Recommendation Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# 1. Popularity-based recommendation\n",
    "def popularity_recommender(interactions_df, top_n=5):\n",
    "    \"\"\"Recommend the most popular rewards.\"\"\"\n",
    "    # Count claims per reward\n",
    "    reward_popularity = interactions_df['reward_id'].value_counts().reset_index()\n",
    "    reward_popularity.columns = ['reward_id', 'claim_count']\n",
    "    \n",
    "    # Sort by popularity\n",
    "    reward_popularity = reward_popularity.sort_values('claim_count', ascending=False)\n",
    "    \n",
    "    # Return top N rewards\n",
    "    return reward_popularity.head(top_n)['reward_id'].tolist()\n",
    "\n",
    "# 2. Collaborative Filtering with Surprise\n",
    "def collaborative_filtering_recommender(interactions_df, customer_id, reward_ids, top_n=5):\n",
    "    \"\"\"Recommend rewards using collaborative filtering.\"\"\"\n",
    "    # Prepare data for Surprise\n",
    "    reader = Reader(rating_scale=(0, 1))\n",
    "    data = Dataset.load_from_df(interactions_df[['customer_id', 'reward_id', 'rating']], reader)\n",
    "    \n",
    "    # Train model\n",
    "    algo = SVD()\n",
    "    trainset = data.build_full_trainset()\n",
    "    algo.fit(trainset)\n",
    "    \n",
    "    # Generate predictions for all rewards not yet claimed by the customer\n",
    "    claimed_rewards = interactions_df[interactions_df['customer_id'] == customer_id]['reward_id'].tolist()\n",
    "    recommendations = []\n",
    "    \n",
    "    for reward_id in reward_ids:\n",
    "        if reward_id not in claimed_rewards:\n",
    "            # Predict rating\n",
    "            prediction = algo.predict(customer_id, reward_id)\n",
    "            recommendations.append((reward_id, prediction.est))\n",
    "    \n",
    "    # Sort by predicted rating\n",
    "    recommendations.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Return top N rewards\n",
    "    return [rec[0] for rec in recommendations[:top_n]]\n",
    "\n",
    "# 3. Content-based recommendation\n",
    "def content_based_recommender(customer_id, customer_features_df, reward_features_df, top_n=5):\n",
    "    \"\"\"Recommend rewards based on customer-reward feature similarity.\"\"\"\n",
    "    # Get customer features\n",
    "    if customer_id not in customer_features_df.index:\n",
    "        return []  # Customer not found\n",
    "        \n",
    "    customer_vec = customer_features_df.loc[customer_id]\n",
    "    \n",
    "    # Calculate similarity scores for each reward\n",
    "    similarity_scores = []\n",
    "    \n",
    "    for reward_id, reward_vec in reward_features_df.iterrows():\n",
    "        score = 0.0\n",
    "        \n",
    "        # Base score on reward value (higher is better, but diminishing returns)\n",
    "        score += np.log1p(reward_vec['value']) * 0.3\n",
    "        \n",
    "        # Adjust for minimum purchase requirement\n",
    "        if reward_vec['has_min_purchase'] == 1:\n",
    "            score -= np.log1p(reward_vec['min_purchase_value']) * 0.1\n",
    "        \n",
    "        # Boost score for rewards matching customer interests\n",
    "        interest_columns = [col for col in customer_vec.index if col.startswith('interest_') and col != 'interest_count']\n",
    "        interests_match = False\n",
    "        \n",
    "        for col in interest_columns:\n",
    "            if customer_vec[col] == 1:\n",
    "                interest = col.replace('interest_', '')\n",
    "                if interest in reward_vec['type'].lower():\n",
    "                    interests_match = True\n",
    "                    break\n",
    "                    \n",
    "        if interests_match:\n",
    "            score += 1.0\n",
    "            \n",
    "        # Gender-specific adjustments (example)\n",
    "        if customer_vec['gender_female'] == 1 and 'beauty' in reward_vec['type'].lower():\n",
    "            score += 0.5\n",
    "            \n",
    "        if customer_vec['gender_male'] == 1 and 'sports' in reward_vec['type'].lower():\n",
    "            score += 0.5\n",
    "            \n",
    "        # Age-based adjustments\n",
    "        age = customer_vec['age']\n",
    "        if age < 30 and 'technology' in reward_vec['type'].lower():\n",
    "            score += 0.5\n",
    "        elif age > 50 and 'home' in reward_vec['type'].lower():\n",
    "            score += 0.5\n",
    "            \n",
    "        similarity_scores.append((reward_id, score))\n",
    "    \n",
    "    # Sort by similarity score\n",
    "    similarity_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Return top N rewards\n",
    "    return [rec[0] for rec in similarity_scores[:top_n]]\n",
    "\n",
    "# 4. Hybrid recommender (combining collaborative and content-based)\n",
    "def hybrid_recommender(customer_id, interactions_df, customer_features_df, reward_features_df, top_n=5):\n",
    "    \"\"\"Hybrid recommendation combining collaborative and content-based approaches.\"\"\"\n",
    "    # Get recommendations from both methods\n",
    "    try:\n",
    "        collab_recs = collaborative_filtering_recommender(\n",
    "            interactions_df, customer_id, reward_features_df.index.tolist(), top_n=top_n*2\n",
    "        )\n",
    "    except:\n",
    "        # Fallback if collaborative filtering fails\n",
    "        collab_recs = []\n",
    "        \n",
    "    content_recs = content_based_recommender(\n",
    "        customer_id, customer_features_df, reward_features_df, top_n=top_n*2\n",
    "    )\n",
    "    \n",
    "    # Combine recommendations with weighting\n",
    "    combined_scores = {}\n",
    "    \n",
    "    # Score collaborative recommendations\n",
    "    for i, reward_id in enumerate(collab_recs):\n",
    "        # Reverse rank scoring (higher rank = higher score)\n",
    "        combined_scores[reward_id] = combined_scores.get(reward_id, 0) + (top_n*2 - i) * 0.6\n",
    "        \n",
    "    # Score content-based recommendations\n",
    "    for i, reward_id in enumerate(content_recs):\n",
    "        # Reverse rank scoring (higher rank = higher score)\n",
    "        combined_scores[reward_id] = combined_scores.get(reward_id, 0) + (top_n*2 - i) * 0.4\n",
    "        \n",
    "    # Sort by combined score\n",
    "    sorted_rewards = sorted(combined_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Return top N rewards\n",
    "    return [rec[0] for rec in sorted_rewards[:top_n]]\n",
    "\n",
    "# 5. Context-aware recommender with multi-armed bandit approach\n",
    "class ContextualBanditRecommender:\n",
    "    \"\"\"Context-aware recommender using Thompson Sampling.\"\"\"\n",
    "    \n",
    "    def __init__(self, reward_ids):\n",
    "        self.reward_ids = reward_ids\n",
    "        self.alpha = {reward_id: 1.0 for reward_id in reward_ids}  # Successes\n",
    "        self.beta = {reward_id: 1.0 for reward_id in reward_ids}   # Failures\n",
    "        self.context_weights = {}  # Contextual weights\n",
    "        \n",
    "    def update(self, reward_id, success, context=None):\n",
    "        \"\"\"Update model based on reward outcome.\"\"\"\n",
    "        if success:\n",
    "            self.alpha[reward_id] += 1.0\n",
    "        else:\n",
    "            self.beta[reward_id] += 1.0\n",
    "            \n",
    "        # Update contextual weights if context provided\n",
    "        if context is not None:\n",
    "            for key, value in context.items():\n",
    "                context_key = f\"{key}:{value}\"\n",
    "                if context_key not in self.context_weights:\n",
    "                    self.context_weights[context_key] = {reward_id: {'alpha': 1.0, 'beta': 1.0} for reward_id in self.reward_ids}\n",
    "                    \n",
    "                if success:\n",
    "                    self.context_weights[context_key][reward_id]['alpha'] += 1.0\n",
    "                else:\n",
    "                    self.context_weights[context_key][reward_id]['beta'] += 1.0\n",
    "    \n",
    "    def recommend(self, top_n=5, context=None):\n",
    "        \"\"\"Recommend rewards using Thompson Sampling.\"\"\"\n",
    "        # Sample from beta distributions\n",
    "        samples = {}\n",
    "        \n",
    "        for reward_id in self.reward_ids:\n",
    "            # Base sample\n",
    "            base_sample = np.random.beta(self.alpha[reward_id], self.beta[reward_id])\n",
    "            samples[reward_id] = base_sample\n",
    "            \n",
    "            # Apply contextual adjustments if context provided\n",
    "            if context is not None:\n",
    "                context_adjustment = 0.0\n",
    "                context_count = 0\n",
    "                \n",
    "                for key, value in context.items():\n",
    "                    context_key = f\"{key}:{value}\"\n",
    "                    if context_key in self.context_weights and reward_id in self.context_weights[context_key]:\n",
    "                        context_weights = self.context_weights[context_key][reward_id]\n",
    "                        context_sample = np.random.beta(context_weights['alpha'], context_weights['beta'])\n",
    "                        context_adjustment += context_sample\n",
    "                        context_count += 1\n",
    "                        \n",
    "                if context_count > 0:\n",
    "                    context_adjustment /= context_count\n",
    "                    samples[reward_id] = 0.7 * base_sample + 0.3 * context_adjustment\n",
    "        \n",
    "        # Sort by sampled values\n",
    "        sorted_samples = sorted(samples.items(), key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        # Return top N rewards\n",
    "        return [rec[0] for rec in sorted_samples[:top_n]]\n",
    "\n",
    "# Initialize bandit recommender\n",
    "bandit_recommender = ContextualBanditRecommender(reward_features_df.index.tolist())\n",
    "\n",
    "# Simulate some learning for the bandit\n",
    "for _ in range(100):\n",
    "    # Randomly select a customer and context\n",
    "    customer_id = np.random.choice(customer_features_df.index)\n",
    "    customer_data = customer_features_df.loc[customer_id]\n",
    "    \n",
    "    context = {\n",
    "        'age_group': 'young' if customer_data['age'] < 30 else 'middle' if customer_data['age'] < 60 else 'senior',\n",
    "        'gender': 'male' if customer_data['gender_male'] == 1 else 'female' if customer_data['gender_female'] == 1 else 'other'\n",
    "    }\n",
    "    \n",
    "    # Recommend a reward\n",
    "    recommendations = bandit_recommender.recommend(top_n=1, context=context)\n",
    "    if recommendations:\n",
    "        reward_id = recommendations[0]\n",
    "        \n",
    "        # Simulate outcome (more likely to succeed if matching interests or high value)\n",
    "        reward_data = reward_features_df.loc[reward_id]\n",
    "        \n",
    "        # Base success probability\n",
    "        success_prob = 0.3\n",
    "        \n",
    "        # Adjust for reward value\n",
    "        success_prob += min(0.3, reward_data['value'] / 100.0)\n",
    "        \n",
    "        # Adjust for demographic match\n",
    "        if (context['gender'] == 'female' and 'beauty' in reward_data['type'].lower()) or \\\n",
    "           (context['gender'] == 'male' and 'sports' in reward_data['type'].lower()):\n",
    "            success_prob += 0.2\n",
    "            \n",
    "        # Simulate outcome\n",
    "        success = np.random.random() < success_prob\n",
    "        \n",
    "        # Update model\n",
    "        bandit_recommender.update(reward_id, success, context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Recommendation Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Create evaluation dataset\n",
    "# Split interactions into train and test\n",
    "train_df, test_df = train_test_split(interactions_df, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Training set: {len(train_df)} interactions\")\n",
    "print(f\"Test set: {len(test_df)} interactions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Evaluate popularity-based recommender\n",
    "popular_rewards = popularity_recommender(train_df, top_n=10)\n",
    "print(f\"Top 10 popular rewards: {popular_rewards}\")\n",
    "\n",
    "# Calculate hit rate (how often the claimed reward is in the recommendations)\n",
    "hit_count = 0\n",
    "for _, row in test_df.iterrows():\n",
    "    if row['reward_id'] in popular_rewards:\n",
    "        hit_count += 1\n",
    "        \n",
    "popularity_hit_rate = hit_count / len(test_df) if len(test_df) > 0 else 0\n",
    "print(f\"Popularity-based hit rate: {popularity_hit_rate:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Evaluate collaborative filtering recommender\n",
    "# Use a subset of test customers for faster evaluation\n",
    "test_customers = test_df['customer_id'].unique()[:10]\n",
    "collab_hit_rates = []\n",
    "\n",
    "for customer_id in test_customers:\n",
    "    # Get claimed rewards for this customer in test set\n",
    "    claimed_rewards = test_df[test_df['customer_id'] == customer_id]['reward_id'].tolist()\n",
    "    \n",
    "    if not claimed_rewards:\n",
    "        continue\n",
    "        \n",
    "    # Get recommendations\n",
    "    try:\n",
    "        recommendations = collaborative_filtering_recommender(\n",
    "            train_df, customer_id, reward_features_df.index.tolist(), top_n=10\n",
    "        )\n",
    "    except:\n",
    "        continue\n",
    "        \n",
    "    # Calculate hit rate\n",
    "    hits = sum(1 for reward_id in claimed_rewards if reward_id in recommendations)\n",
    "    hit_rate = hits / len(claimed_rewards) if claimed_rewards else 0\n",
    "    collab_hit_rates.append(hit_rate)\n",
    "\n",
    "collab_avg_hit_rate = np.mean(collab_hit_rates) if collab_hit_rates else 0\n",
    "print(f\"Collaborative filtering average hit rate: {collab_avg_hit_rate:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Evaluate content-based recommender\n",
    "content_hit_rates = []\n",
    "\n",
    "for customer_id in test_customers:\n",
    "    # Get claimed rewards for this customer in test set\n",
    "    claimed_rewards = test_df[test_df['customer_id'] == customer_id]['reward_id'].tolist()\n",
    "    \n",
    "    if not claimed_rewards:\n",
    "        continue\n",
    "        \n",
    "    # Get recommendations\n",
    "    recommendations = content_based_recommender(\n",
    "        customer_id, customer_features_df, reward_features_df, top_n=10\n",
    "    )\n",
    "        \n",
    "    # Calculate hit rate\n",
    "    hits = sum(1 for reward_id in claimed_rewards if reward_id in recommendations)\n",
    "    hit_rate = hits / len(claimed_rewards) if claimed_rewards else 0\n",
    "    content_hit_rates.append(hit_rate)\n",
    "\n",
    "content_avg_hit_rate = np.mean(content_hit_rates) if content_hit_rates else 0\n",
    "print(f\"Content-based average hit rate: {content_avg_hit_rate:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Evaluate hybrid recommender\n",
    "hybrid_hit_rates = []\n",
    "\n",
    "for customer_id in test_customers:\n",
    "    # Get claimed rewards for this customer in test set\n",
    "    claimed_rewards = test_df[test_df['customer_id'] == customer_id]['reward_id'].tolist()\n",
    "    \n",
    "    if not claimed_rewards:\n",
    "        continue\n",
    "        \n",
    "    # Get recommendations\n",
    "    try:\n",
    "        recommendations = hybrid_recommender(\n",
    "            customer_id, train_df, customer_features_df, reward_features_df, top_n=10\n",
    "        )\n",
    "    except:\n",
    "        continue\n",
    "        \n",
    "    # Calculate hit rate\n",
    "    hits = sum(1 for reward_id in claimed_rewards if reward_id in recommendations)\n",
    "    hit_rate = hits / len(claimed_rewards) if claimed_rewards else 0\n",
    "    hybrid_hit_rates.append(hit_rate)\n",
    "\n",
    "hybrid_avg_hit_rate = np.mean(hybrid_hit_rates) if hybrid_hit_rates else 0\n",
    "print(f\"Hybrid recommender average hit rate: {hybrid_avg_hit_rate:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Evaluate contextual bandit recommender\n",
    "bandit_hit_rates = []\n",
    "\n",
    "for customer_id in test_customers:\n",
    "    # Get claimed rewards for this customer in test set\n",
    "    claimed_rewards = test_df[test_df['customer_id'] == customer_id]['reward_id'].tolist()\n",
    "    \n",
    "    if not claimed_rewards or customer_id not in customer_features_df.index:\n",
    "        continue\n",
    "        \n",
    "    # Get customer context\n",
    "    customer_data = customer_features_df.loc[customer_id]\n",
    "    \n",
    "    context = {\n",
    "        'age_group': 'young' if customer_data['age'] < 30 else 'middle' if customer_data['age'] < 60 else 'senior',\n",
    "        'gender': 'male' if customer_data['gender_male'] == 1 else 'female' if customer_data['gender_female'] == 1 else 'other'\n",
    "    }\n",
    "    \n",
    "    # Get recommendations\n",
    "    recommendations = bandit_recommender.recommend(top_n=10, context=context)\n",
    "        \n",
    "    # Calculate hit rate\n",
    "    hits = sum(1 for reward_id in claimed_rewards if reward_id in recommendations)\n",
    "    hit_rate = hits / len(claimed_rewards) if claimed_rewards else 0\n",
    "    bandit_hit_rates.append(hit_rate)\n",
    "\n",
    "bandit_avg_hit_rate = np.mean(bandit_hit_rates) if bandit_hit_rates else 0\n",
    "print(f\"Contextual bandit recommender average hit rate: {bandit_avg_hit_rate:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Compare hit rates\n",
    "algorithms = ['Popularity', 'Collaborative', 'Content-based', 'Hybrid', 'Contextual Bandit']\n",
    "hit_rates = [popularity_hit_rate, collab_avg_hit_rate, content_avg_hit_rate, hybrid_avg_hit_rate, bandit_avg_hit_rate]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(algorithms, hit_rates, color='skyblue')\n",
    "plt.title('Recommendation Algorithm Performance Comparison')\n",
    "plt.xlabel('Algorithm')\n",
    "plt.ylabel('Hit Rate')\n",
    "plt.ylim(0, max(hit_rates) * 1.2)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Add values on top of bars\n",
    "for i, v in enumerate(hit_rates):\n",
    "    plt.text(i, v + 0.01, f\"{v:.4f}\", ha='center')\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement Final Hybrid Recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def final_recommender(customer_id, interactions_df, customer_features_df, reward_features_df, reward_bandit=None, top_n=5):\n",
    "    \"\"\"Final hybrid recommendation algorithm combining all approaches.\"\"\"\n",
    "    # Try collaborative filtering\n",
    "    try:\n",
    "        collab_recs = collaborative_filtering_recommender(\n",
    "            interactions_df, customer_id, reward_features_df.index.tolist(), top_n=top_n*2\n",
    "        )\n",
    "    except:\n",
    "        # Fallback to popular rewards if collaborative filtering fails\n",
    "        collab_recs = popularity_recommender(interactions_df, top_n=top_n*2)\n",
    "        \n",
    "    # Get content-based recommendations\n",
    "    if customer_id in customer_features_df.index:\n",
    "        content_recs = content_based_recommender(\n",
    "            customer_id, customer_features_df, reward_features_df, top_n=top_n*2\n",
    "        )\n",
    "    else:\n",
    "        content_recs = []\n",
    "        \n",
    "    # Get bandit recommendations if available\n",
    "    if reward_bandit is not None and customer_id in customer_features_df.index:\n",
    "        customer_data = customer_features_df.loc[customer_id]\n",
    "        context = {\n",
    "            'age_group': 'young' if customer_data['age'] < 30 else 'middle' if customer_data['age'] < 60 else 'senior',\n",
    "            'gender': 'male' if customer_data['gender_male'] == 1 else 'female' if customer_data['gender_female'] == 1 else 'other'\n",
    "        }\n",
    "        bandit_recs = reward_bandit.recommend(top_n=top_n*2, context=context)\n",
    "    else:\n",
    "        bandit_recs = []\n",
    "    \n",
    "    # Combine all recommendations with weights\n",
    "    combined_scores = {}\n",
    "    \n",
    "    # Assign weights to each approach\n",
    "    weights = {\n",
    "        'collaborative': 0.4,\n",
    "        'content': 0.3,\n",
    "        'bandit': 0.3\n",
    "    }\n",
    "    \n",
    "    # Score collaborative recommendations\n",
    "    for i, reward_id in enumerate(collab_recs):\n",
    "        # Reverse rank scoring (higher rank = higher score)\n",
    "        combined_scores[reward_id] = combined_scores.get(reward_id, 0) + \\\n",
    "                                      (top_n*2 - i) / (top_n*2) * weights['collaborative']\n",
    "        \n",
    "    # Score content-based recommendations\n",
    "    for i, reward_id in enumerate(content_recs):\n",
    "        # Reverse rank scoring (higher rank = higher score)\n",
    "        combined_scores[reward_id] = combined_scores.get(reward_id, 0) + \\\n",
    "                                      (top_n*2 - i) / (top_n*2) * weights['content']\n",
    "        \n",
    "    # Score bandit recommendations\n",
    "    for i, reward_id in enumerate(bandit_recs):\n",
    "        # Reverse rank scoring (higher rank = higher score)\n",
    "        combined_scores[reward_id] = combined_scores.get(reward_id, 0) + \\\n",
    "                                      (top_n*2 - i) / (top_n*2) * weights['bandit']\n",
    "        \n",
    "    # Sort by combined score\n",
    "    sorted_rewards = sorted(combined_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Return top N rewards\n",
    "    return [rec[0] for rec in sorted_rewards[:top_n]]\n",
    "\n",
    "# Test final recommender\n",
    "test_customer = test_customers[0] if test_customers else customer_features_df.index[0]\n",
    "final_recommendations = final_recommender(\n",
    "    test_customer, interactions_df, customer_features_df, reward_features_df, \n",
    "    reward_bandit=bandit_recommender, top_n=5\n",
    ")\n",
    "\n",
    "print(f\"Final recommendations for customer {test_customer}:\")\n",
    "for i, reward_id in enumerate(final_recommendations):\n",
    "    reward_name = rewards_df[rewards_df['id'] == reward_id]['name'].values[0] if reward_id in rewards_df['id'].values else \"Unknown\"\n",
    "    print(f\"{i+1}. {reward_name} (ID: {reward_id})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Final Recommender Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import pickle\n",
    "\n",
    "# Create a model package for export\n",
    "recommender_package = {\n",
    "    'bandit_recommender': bandit_recommender,\n",
    "    'customer_features_df': customer_features_df,\n",
    "    'reward_features_df': reward_features_df,\n",
    "    'interactions_df': interactions_df,\n",
    "    'recommender_function': final_recommender\n",
    "}\n",
    "\n",
    "# Save the model package\n",
    "with open('../data/processed/reward_recommender_model.pkl', 'wb') as f:\n",
    "    pickle.dump(recommender_package, f)\n",
    "    \n",
    "print(\"Saved recommender model to '../data/processed/reward_recommender_model.pkl'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
